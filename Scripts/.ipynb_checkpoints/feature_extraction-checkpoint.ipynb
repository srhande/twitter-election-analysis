{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using 3 Techniques\n",
    "\n",
    "The text below will explain what feature extraction is, and how we can go about doing it.\n",
    "\n",
    "## How do we even begin to classify sentiments of sentences?\n",
    "Our project requires us to analyze the sentiments of tweets, which (obviously) consist of sentences and words. Sentences, of course, can come in numerous variations, and can also be considered unstructured due to this inconsistency between sentences. \n",
    "\n",
    "However, machine learning techniques that we use structured data in order to properly train models. So, how do we do train models on sentences?\n",
    "\n",
    "In the domain of Natural Language Processing (NLP), there are several techniques of **feature extraction**, or ways in which to structure text. As stated in [this paper on text classification algorithms](https://arxiv.org/pdf/1904.08067.pdf), feature extraction techniques serves to convert unstructured text sequences into a structured feature space once the textual data itself has been cleaned.\n",
    "\n",
    "For the purposes of this project, we will be looking at three of such techniques: **Bag-of-Words**, **Term Frequency-Inverse Document Frequency**, and **Word2Vec**.\n",
    "\n",
    "## How do we go about cleaning textual data?\n",
    "There are many ways in which to clean textual data, many of which are mentioned in the aforementioned paper. Some of these include tokenization, which breaks sentences into meaningful chunks (e.g. words or symbols) that are called tokens.\n",
    "Others include removing whitespace and special characters, converting all letters to lower-case, or removing stop words i.e. words that do not contain important significance such as *\"a\"* or *\"the\"*.\n",
    "\n",
    "## What is Bag-of-Words?\n",
    "The Bag-of-Words (BoW) model seeks to reduce and simplify text based on a specific criteria, most commonly word frequency. Think of a body of text as a literal bag of words (or list of words), where our feature space becomes the frequency that each word occurs in the text. The logic behind this is that words are often representative of the content of the sentence, so if a particular noun appears many times, then one can assume that the subject of that sentence has to do with that noun.\n",
    "\n",
    "[Wikipedia provides an excellent example of how this would exactly look like, and how this would work in spam filtering](https://en.wikipedia.org/wiki/Bag-of-words_model).\n",
    "\n",
    "However, there are some limitations of this approach. BoW ignores grammar and order of appearance of words e.g. \"Is this true\" and \"This is true\" both have the same feature space. There are also issues of scalability. However, since tweets have a character limit of 280 characters, we do not think this will be much of a problem.\n",
    "\n",
    "[Here is a blog showing what Bag-of-Words is mathematically, and how to use it in conjunction with a Naive Bayes Classifier to analyze the sentiments of movie reviews](https://www.datacamp.com/community/tutorials/simplifying-sentiment-analysis-python).\n",
    "\n",
    "## What is Term Frequency-Inverse Document Frequency?\n",
    "Term Frequency-Inverse Document Frequency, otherwise known as TF-IDF, is another method of feature extraction, and is used to determine *how* important a word is to a document. How does it determine the importance of a word? It helps to explain this by first defining what these two terms mean.\n",
    "\n",
    "Term Frequency refers to the raw count of a term in a document. It is similar to how the Bag-of-Words model works, and just looks at the true frequency of some specific term.\n",
    "\n",
    "Whereas Term Frequency deals with the raw count of a term, Inverse Document Frequency refers to giving more *weight* to the uncommon terms, while giving less *weight* to more common terms This is calculated as an inverse function of the number of documents the term appears in.\n",
    "\n",
    "[Again, Wikipedia provides a good example of how this works out in finding documents relating to a specific query](https://en.wikipedia.org/wiki/Tf%E2%80%93idf#Term_frequency_2).\n",
    "\n",
    "Though TF-IDF gives weight to less common words, which helps lessen the effect common words have, this technique still has its cons. It cannot account for the similarity between words in a document, as each word is independently presented as an index. Also, since it is based off of the BoW Model, it does not capture positions in text or the semantics of the sentence.\n",
    "\n",
    "## What is Word2Vec?\n",
    "Word2Vec, short for *word to vector*, is an improvement on existing word embedding techniques. What is [word embedding](https://en.wikipedia.org/wiki/Word_embedding)? In short, these refer to NLP techniques that mapping words or phrases to vectors of real numbers i.e. a mapping of a space with many dimensions to a continuous vector space with much lower dimensions.\n",
    "\n",
    "What makes Word2Vec stand out? Word2Vec uses shallow neural networks with just 2 hidden layers trained to reconstruct the linguistic contexts of words. These models take as input a large corpus of words and creates a vector space of (usually) several hundred dimensions, where each unique word is given a vector in that vector space. Word vectors sharing a common context are closer to each other in that vector space than unrelated words e.g. \"small\" and \"smaller\" are closer than \"small\" and \"sky\".\n",
    "\n",
    "This method provides a means to discover the relationship and similarities between words, which is unattainable for the previous two methods described. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Feature Extraction\n",
    "Below, we begin to code how to use these different feature extraction techniques. We will use the [NLTK library](https://www.nltk.org/) for these different techniques.\n",
    "\n",
    "We will also be using the data set `tweets2020.csv`.\n",
    "\n",
    "First, we import the needed libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@belcherjody1 IF no voter ID required by 2020,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @matthewjdowd: “As we approach this 2020 pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @SisiLiliDidi: #AndrewYang polls 14%--18% a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @PRIMONUTMEG: Are you paying attention to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @davidsirota: Fact check: Zero Pinnochios, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             tweets\n",
       "0   0  @belcherjody1 IF no voter ID required by 2020,...\n",
       "1   1  RT @matthewjdowd: “As we approach this 2020 pr...\n",
       "2   2  RT @SisiLiliDidi: #AndrewYang polls 14%--18% a...\n",
       "3   3  RT @PRIMONUTMEG: Are you paying attention to t...\n",
       "4   4  RT @davidsirota: Fact check: Zero Pinnochios, ..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Bag of Words imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tweets_df = pd.read_csv('tweets2020.csv')\n",
    "tweets_df.columns = ['id', 'tweets']\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleans a tweet by removing @names, links, special characters, empty tweets, \n",
    "duplicate tweets, stop-words, and converting all letters to lower-case.\n",
    "This function also stems each word in the tweet.\n",
    "\n",
    "# Want to apply this function to each row\n",
    "\"\"\"\n",
    "def clean_tweet(tweet):\n",
    "    # Remove @names\n",
    "    name_regex = \"@[\\_0-9a-zA-Z]+\\:? | *RT*\"\n",
    "    cleaned_tweet = re.sub(name_regex, \"\", tweet)\n",
    "    \n",
    "    # Remove links\n",
    "    url_regex = \"(https?:\\/\\/)(\\s)?(www\\.)?(\\s?)(\\w+\\.)*([\\w\\-\\s]+\\/)*([\\w-]+)\\/?\"\n",
    "    cleaned_tweet = re.sub(url_regex, \"\", cleaned_tweet)\n",
    "    \n",
    "    # TODO: Remove special characters\n",
    "    \n",
    "    # TODO: Remove empty tweets\n",
    "    \n",
    "    # TODO: Remove duplicates\n",
    "    \n",
    "    # TODO: Remove stop-words\n",
    "    \n",
    "    # TODO: Stem words\n",
    "    \n",
    "    # TODO: Convert to lower-case\n",
    "    \n",
    "    return cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'=( asdfghjkl'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = \"=( asdfghjkl\"\n",
    "clean_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df['cleaned_tweets'] = tweets_df['tweets'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@belcherjody1 IF no voter ID required by 2020,...</td>\n",
       "      <td>IF no voter ID required by 2020, Trump will lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @matthewjdowd: “As we approach this 2020 pr...</td>\n",
       "      <td>“As we approach this 2020 presidential campai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @SisiLiliDidi: #AndrewYang polls 14%--18% a...</td>\n",
       "      <td>#AndrewYang polls 14%--18% among Gen Z, but 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @PRIMONUTMEG: Are you paying attention to t...</td>\n",
       "      <td>Are you paying attention to the Green Party P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @davidsirota: Fact check: Zero Pinnochios, ...</td>\n",
       "      <td>Fact check: Zero Pinnochios, Bottomless Geppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>RT @OddsShark: Updated odds to be the Democrat...</td>\n",
       "      <td>Updated odds to be the Democratic Candidate f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>RT @Rachel_K_Chen: 420 more days until the pre...</td>\n",
       "      <td>420 more days until the presidential election...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Union members say 2020 labor support for Trump...</td>\n",
       "      <td>Union members say 2020 labor support for Trump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>RT @agitpopworld: @ddale8 “Dear Daddy,\\n\\nHere...</td>\n",
       "      <td>“Dear Daddy,\\n\\nHere's the prototype of an un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>RT @jacobinmag: We asked longtime climate advo...</td>\n",
       "      <td>We asked longtime climate advocates which can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>#AndrewYang polls 14%--18% among Gen Z, but 0%...</td>\n",
       "      <td>#AndrewYang polls 14%--18% among Gen Z, but 0%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>RT @MyConstitution: W/the #2020 presidential e...</td>\n",
       "      <td>W/the #2020 presidential election quickly app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>RT @PostTech: Federal law enforcement official...</td>\n",
       "      <td>Federal law enforcement officials huddled wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>RT @Aliciastarr001: WATCH VIDEO:\\nA former Goo...</td>\n",
       "      <td>WATCH VIDEO:\\nA former Google employee sounde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>What can we learn from the 2016 election going...</td>\n",
       "      <td>What can we learn from the 2016 election going...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                             tweets  \\\n",
       "0    0  @belcherjody1 IF no voter ID required by 2020,...   \n",
       "1    1  RT @matthewjdowd: “As we approach this 2020 pr...   \n",
       "2    2  RT @SisiLiliDidi: #AndrewYang polls 14%--18% a...   \n",
       "3    3  RT @PRIMONUTMEG: Are you paying attention to t...   \n",
       "4    4  RT @davidsirota: Fact check: Zero Pinnochios, ...   \n",
       "5    5  RT @OddsShark: Updated odds to be the Democrat...   \n",
       "6    6  RT @Rachel_K_Chen: 420 more days until the pre...   \n",
       "7    7  Union members say 2020 labor support for Trump...   \n",
       "8    8  RT @agitpopworld: @ddale8 “Dear Daddy,\\n\\nHere...   \n",
       "9    9  RT @jacobinmag: We asked longtime climate advo...   \n",
       "10  10  #AndrewYang polls 14%--18% among Gen Z, but 0%...   \n",
       "11  11  RT @MyConstitution: W/the #2020 presidential e...   \n",
       "12  12  RT @PostTech: Federal law enforcement official...   \n",
       "13  13  RT @Aliciastarr001: WATCH VIDEO:\\nA former Goo...   \n",
       "14  14  What can we learn from the 2016 election going...   \n",
       "\n",
       "                                       cleaned_tweets  \n",
       "0   IF no voter ID required by 2020, Trump will lo...  \n",
       "1    “As we approach this 2020 presidential campai...  \n",
       "2    #AndrewYang polls 14%--18% among Gen Z, but 0...  \n",
       "3    Are you paying attention to the Green Party P...  \n",
       "4    Fact check: Zero Pinnochios, Bottomless Geppe...  \n",
       "5    Updated odds to be the Democratic Candidate f...  \n",
       "6    420 more days until the presidential election...  \n",
       "7   Union members say 2020 labor support for Trump...  \n",
       "8    “Dear Daddy,\\n\\nHere's the prototype of an un...  \n",
       "9    We asked longtime climate advocates which can...  \n",
       "10  #AndrewYang polls 14%--18% among Gen Z, but 0%...  \n",
       "11   W/the #2020 presidential election quickly app...  \n",
       "12   Federal law enforcement officials huddled wit...  \n",
       "13   WATCH VIDEO:\\nA former Google employee sounde...  \n",
       "14  What can we learn from the 2016 election going...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
