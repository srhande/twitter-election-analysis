{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filename: get_data.pynb\n",
    "\n",
    "# Purpose:\n",
    "\n",
    "This script will download the tweets we need for our project and put them into a pandas DataFrame. There are several ways we can get the data we need for our project.\n",
    "\n",
    "As of right now, we use two methods to get the data we need: through using specific keywords regarding the 2020 Presidential Election and by scraping tweets with hashtags regarding the 2020 Presidential election and its candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0 (from tweepy)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.11.1 in d:\\anaconda\\lib\\site-packages (from tweepy) (2.21.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in d:\\anaconda\\lib\\site-packages (from tweepy) (1.6.8)\n",
      "Requirement already satisfied: six>=1.10.0 in d:\\anaconda\\lib\\site-packages (from tweepy) (1.12.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->tweepy)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.11.1->tweepy) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.11.1->tweepy) (1.24.1)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tweepy\n",
      "Successfully installed oauthlib-3.1.0 requests-oauthlib-1.2.0 tweepy-3.8.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install tweepy # Run this line only if you don't have tweepy installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tweepy \n",
    "from tweepy import OAuthHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Tweets using Twitter API with `Tweepy`\n",
    "\n",
    "The below class is made using [this code](https://www.kaggle.com/amar09/sentiment-analysis-on-scrapped-tweets?source=post_page-----1804db3478ac----------------------) from Kaggle User [Amardeep Chauhan](https://www.kaggle.com/amar09). \n",
    "\n",
    "The class uses `tweepy` to access the Twitter API and fetch tweets relating to a specified keyword. \n",
    "\n",
    "The keywords we will use are:\n",
    "\n",
    "- 2020 Presidential Election\n",
    "- TODO: Come up with more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keys and tokens\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "\n",
    "access_token = ''\n",
    "access_token_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient(object):\n",
    "    \"\"\"\n",
    "    Initialization method. Creates a tweepy API object in order to use tweets.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            # Create OAuthHandler Object\n",
    "            auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            \n",
    "            # Set access token and secret token\n",
    "            auth.set_access_token(access_token, access_token_secret)\n",
    "            \n",
    "            # Create tweepy API object to fetch tweets\n",
    "            self.api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n",
    "            \n",
    "        except tweepy.TweepError as e:\n",
    "            print(f'Error: Tweeter Authentication Failed - \\n{str(e)}')\n",
    "            \n",
    "    \"\"\"\n",
    "    Fetches tweets using a specified query. Stores the tweets in a list after\n",
    "    parsing them.\n",
    "    \n",
    "    TODO: Documentation\n",
    "    \"\"\"\n",
    "    def get_tweets(self, query, max_tweets = 1000):\n",
    "        tweets = []\n",
    "        since_Id = None\n",
    "        max_id = -1\n",
    "        tweet_count = 0\n",
    "        tweets_per_query = 100\n",
    "        \n",
    "        while tweet_count < max_tweets:\n",
    "            try:\n",
    "                # TODO: Figure out what these if-else statements do\n",
    "                if(max_id <= 0):\n",
    "                    if(not since_Id):\n",
    "                        new_tweets = self.api.search(q = query, count = tweets_per_query)\n",
    "                        \n",
    "                    else:\n",
    "                        new_tweets = self.api.search(q = query, count = tweets_per_query, since_id = since_Id)\n",
    "                else:\n",
    "                    if(not since_Id):\n",
    "                        new_tweets = self.api.search(q = query, count = tweets_per_query, max_id = str(max_id - 1))\n",
    "                        \n",
    "                    else:\n",
    "                        new_tweets = self.api.search(q = query, count = tweets_per_query, max_id = str(max_id - 1), \n",
    "                                                     since_id = since_Id)\n",
    "                \n",
    "                if not new_tweets:\n",
    "                    print('No more tweets found.')\n",
    "                    break\n",
    "                \n",
    "                # Start parsing the list of tweets\n",
    "                for tweet in new_tweets:\n",
    "                    parsed_tweet = {}\n",
    "                    parsed_tweet['tweets'] = tweet.text\n",
    "                    \n",
    "                    # Append parsed tweet to tweets list\n",
    "                    if tweet.retweet_count > 0: \n",
    "                        if parsed_tweet not in tweets: # If tweet has retweets, ensure that its appended only once\n",
    "                            tweets.append(parsed_tweet)\n",
    "                    else:\n",
    "                        tweets.append(parsed_tweet)\n",
    "                \n",
    "                tweet_count += len(new_tweets)\n",
    "                print('Downloaded {0} tweets'.format(tweet_count))\n",
    "                max_id = new_tweets[-1].id\n",
    "                \n",
    "            except tweepy.TweepError as e: # Exit if there are any errors\n",
    "                print('Tweepy Error: ' + str(e))\n",
    "                break\n",
    "                \n",
    "        \n",
    "        # Return DataFrame of tweets\n",
    "        return pd.DataFrame(tweets)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 100 tweets\n",
      "Downloaded 200 tweets\n",
      "Downloaded 300 tweets\n",
      "Downloaded 400 tweets\n",
      "Downloaded 500 tweets\n",
      "Downloaded 600 tweets\n",
      "Downloaded 700 tweets\n",
      "Downloaded 800 tweets\n",
      "Downloaded 900 tweets\n",
      "Downloaded 1000 tweets\n",
      "tweets_df Shape - (76, 1)\n"
     ]
    }
   ],
   "source": [
    "twitter_client = TwitterClient()\n",
    "\n",
    "# Create dataframe of tweets\n",
    "tweets_df = twitter_client.get_tweets('2020 Presidential Election', max_tweets = 1000)\n",
    "print(f'tweets_df Shape - {tweets_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @JoshRudes: .@washingtonpost has been \"reli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @PredictIt: Here is the 2020 Presidential w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @ABC: At least three states are considering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @20predict: Taylor Swift will be one of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@mdornic  I would like to thank you for helpin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets\n",
       "0  RT @JoshRudes: .@washingtonpost has been \"reli...\n",
       "1  RT @PredictIt: Here is the 2020 Presidential w...\n",
       "2  RT @ABC: At least three states are considering...\n",
       "3  RT @20predict: Taylor Swift will be one of the...\n",
       "4  @mdornic  I would like to thank you for helpin..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @JoshRudes: .@washingtonpost has been \"reliably told\" that Trump is intentionally withholding a White House visit and US military aid \"i…'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.iloc[0].tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
